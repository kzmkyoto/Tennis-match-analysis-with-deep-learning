{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12177450,"sourceType":"datasetVersion","datasetId":7669422},{"sourceId":12309297,"sourceType":"datasetVersion","datasetId":7712862}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"FCm5coNImzQ3","cell_type":"code","source":"!pwd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCm5coNImzQ3","outputId":"580fdafb-aa3f-496a-ff90-177c6b8bcbb2","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:45.357498Z","iopub.execute_input":"2025-06-28T12:14:45.357787Z","iopub.status.idle":"2025-06-28T12:14:45.527475Z","shell.execute_reply.started":"2025-06-28T12:14:45.357764Z","shell.execute_reply":"2025-06-28T12:14:45.526468Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":57},{"id":"3Lm0aFpRGL4w","cell_type":"markdown","source":"download necessary libraries","metadata":{"id":"3Lm0aFpRGL4w"}},{"id":"mV6zvfTWl1d2","cell_type":"code","source":"!pip install -r /kaggle/input/requirements/requirements2.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mV6zvfTWl1d2","outputId":"b6bde7e0-029f-412d-a0d1-823ad058fa30","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:45.529597Z","iopub.execute_input":"2025-06-28T12:14:45.529858Z","iopub.status.idle":"2025-06-28T12:14:48.646247Z","shell.execute_reply.started":"2025-06-28T12:14:45.529834Z","shell.execute_reply":"2025-06-28T12:14:48.645261Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy==1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 1)) (1.25.0)\nRequirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 2)) (4.11.0.86)\nRequirement already satisfied: pandas==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 3)) (2.3.0)\nRequirement already satisfied: scipy==1.15.0 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 4)) (1.15.0)\nRequirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 5)) (2.7.1)\nRequirement already satisfied: torchvision==0.22.1 in /usr/local/lib/python3.11/dist-packages (from -r /kaggle/input/requirements/requirements2.txt (line 6)) (0.22.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /kaggle/input/requirements/requirements2.txt (line 3)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /kaggle/input/requirements/requirements2.txt (line 3)) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /kaggle/input/requirements/requirements2.txt (line 3)) (2025.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (4.13.2)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (3.3.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.22.1->-r /kaggle/input/requirements/requirements2.txt (line 6)) (11.1.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (75.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.3.0->-r /kaggle/input/requirements/requirements2.txt (line 3)) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->-r /kaggle/input/requirements/requirements2.txt (line 5)) (3.0.2)\n","output_type":"stream"}],"execution_count":58},{"id":"rt80DpFQgrXJ","cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n  print('available')\nelse:\n  print('not available')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rt80DpFQgrXJ","outputId":"7f742c88-dba2-4f30-fccc-2f8e83c70502","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:48.647246Z","iopub.execute_input":"2025-06-28T12:14:48.647520Z","iopub.status.idle":"2025-06-28T12:14:48.652540Z","shell.execute_reply.started":"2025-06-28T12:14:48.647496Z","shell.execute_reply":"2025-06-28T12:14:48.651718Z"}},"outputs":[{"name":"stdout","text":"available\n","output_type":"stream"}],"execution_count":59},{"id":"78f5844b","cell_type":"markdown","source":"# model training","metadata":{"id":"78f5844b"}},{"id":"85f11a17","cell_type":"markdown","source":"## model.py","metadata":{"id":"85f11a17"}},{"id":"56a7349a","cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, pad=1, stride=1, bias=True):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=pad, bias=bias),\n            nn.ReLU(),\n            nn.BatchNorm2d(out_channels)\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\nclass TrackNet(nn.Module):\n    def __init__(self, out_channels=256):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.conv1 = ConvBlock(in_channels=9, out_channels=64)\n        self.conv2 = ConvBlock(in_channels=64, out_channels=64)\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n        self.conv4 = ConvBlock(in_channels=128, out_channels=128)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv5 = ConvBlock(in_channels=128, out_channels=256)\n        self.conv6 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv7 = ConvBlock(in_channels=256, out_channels=256)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv8 = ConvBlock(in_channels=256, out_channels=512)\n        self.conv9 = ConvBlock(in_channels=512, out_channels=512)\n        self.conv10 = ConvBlock(in_channels=512, out_channels=512)\n        self.ups1 = nn.Upsample(scale_factor=2)\n        self.conv11 = ConvBlock(in_channels=512, out_channels=256)\n        self.conv12 = ConvBlock(in_channels=256, out_channels=256)\n        self.conv13 = ConvBlock(in_channels=256, out_channels=256)\n        self.ups2 = nn.Upsample(scale_factor=2)\n        self.conv14 = ConvBlock(in_channels=256, out_channels=128)\n        self.conv15 = ConvBlock(in_channels=128, out_channels=128)\n        self.ups3 = nn.Upsample(scale_factor=2)\n        self.conv16 = ConvBlock(in_channels=128, out_channels=64)\n        self.conv17 = ConvBlock(in_channels=64, out_channels=64)\n        self.conv18 = ConvBlock(in_channels=64, out_channels=self.out_channels)\n\n        self.softmax = nn.Softmax(dim=1)\n        self._init_weights()\n\n    def forward(self, x, testing=False):\n        batch_size = x.size(0)\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.pool1(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.pool2(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.conv7(x)\n        x = self.pool3(x)\n        x = self.conv8(x)\n        x = self.conv9(x)\n        x = self.conv10(x)\n        x = self.ups1(x)\n        x = self.conv11(x)\n        x = self.conv12(x)\n        x = self.conv13(x)\n        x = self.ups2(x)\n        x = self.conv14(x)\n        x = self.conv15(x)\n        x = self.ups3(x)\n        x = self.conv16(x)\n        x = self.conv17(x)\n        x = self.conv18(x)\n        # x = self.softmax(x)\n        out = x.reshape(batch_size, self.out_channels, -1)\n        if testing:\n            out = self.softmax(out)\n        return out\n\n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Conv2d):\n                nn.init.uniform_(module.weight, -0.05, 0.05)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0)\n\n            elif isinstance(module, nn.BatchNorm2d):\n                nn.init.constant_(module.weight, 1)\n                nn.init.constant_(module.bias, 0)\n","metadata":{"id":"56a7349a","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:48.654424Z","iopub.execute_input":"2025-06-28T12:14:48.654631Z","iopub.status.idle":"2025-06-28T12:14:48.670137Z","shell.execute_reply.started":"2025-06-28T12:14:48.654616Z","shell.execute_reply":"2025-06-28T12:14:48.669373Z"}},"outputs":[],"execution_count":60},{"id":"2b92efd6","cell_type":"markdown","source":"## TrackNet_utils.py","metadata":{"id":"2b92efd6"}},{"id":"c97efa7d","cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\n\n\ndef create_gt_labels(root_dir=r'c:/kyoto/TennisML/TrackNet/Dataset', path_csv_output=r'c:/kyoto/TennisML/TrackNet/Dataset', train_propotion=0.7):\n    # Merge label.csv files in each end of clips to one csv file\n\n    df = pd.DataFrame()\n\n    for game_id in range(1, 11):\n        path_game = os.path.join(root_dir, f\"game{game_id}\")\n        clips = os.listdir(path_game)\n        for clip in clips:\n            labels = pd.read_csv(os.path.join(path_game, clip, 'Label.csv'))\n            labels['path_now'] = labels['file name'].apply(lambda k: os.path.join(f\"game{game_id}\", clip, k))\n\n            # labels_gt = labels.iloc[2:].copy()      # remove the first two rows\n            labels_gt = labels.iloc[:].copy()\n            labels_gt.loc[:, 'path_prev'] = labels['path_now'].shift(1)\n            labels_gt.loc[:, 'path_prevprev'] = labels['path_now'].shift(2)\n            labels_gt.loc[:, 'path_gt'] = labels['path_now']\n            labels_gt = labels_gt[2:]\n            df = pd.concat([df, labels_gt], ignore_index=True)\n\n    df = df.loc[:, ['path_now', 'path_prev', 'path_prevprev', 'path_gt', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n    num_train = int(len(df.index)*train_propotion)\n    df_train = df.loc[:num_train]\n    df_val = df.loc[num_train:]\n    df_train.to_csv(os.path.join(path_csv_output, 'labels_train.csv'), index=False)\n    df_val.to_csv(os.path.join(path_csv_output, 'labels_val.csv'), index=False)\n    # print(df_train)\n\n# def create_gt_labels_2(path_input='c:/kyoto/TennisML/TrackNet/Dataset', path_output='c:/kyoto/TennisML/TrackNet/Dataset', train_rate=0.7):\n#     df = pd.DataFrame()\n#     for game_id in range(1,11):\n#         game = 'game{}'.format(game_id)\n#         clips = os.listdir(os.path.join(path_input, game))\n#         for clip in clips:\n#             labels = pd.read_csv(os.path.join(path_input, game, clip, 'Label.csv'))\n#             labels['gt_path'] = 'gts/' + game + '/' + clip + '/' + labels['file name']\n#             labels['path1'] = 'images/' + game + '/' + clip + '/' + labels['file name']\n#             labels_target = labels[2:]\n#             labels_target.loc[:, 'path2'] = list(labels['path1'][1:-1])\n#             labels_target.loc[:, 'path3'] = list(labels['path1'][:-2])\n#             df = pd.concat([df, labels_target], ignore_index=True)\n#     df = df.reset_index(drop=True)\n#     df = df[['path1', 'path2', 'path3', 'gt_path', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n#     # df = df.sample(frac=1)\n#     num_train = int(df.shape[0]*train_rate)\n#     df_train = df[:num_train]\n#     df_test = df[num_train:]\n#     df_train.to_csv(os.path.join(path_output, 'labels_train.csv'), index=False)\n#     df_test.to_csv(os.path.join(path_output, 'labels_val.csv'), index=False)\n\n\ndef gaussian_kernel(size, sigma):\n    '''\n    sigma(variance) is equivalent to the average radius of a tennis ball (about 5 pixels)\n    '''\n    x, y = np.mgrid[-size:size+1, -size:size+1]\n    gk = np.exp( -(x**2 + y**2) / (float(2*sigma)) )\n    return gk\n\ndef generate_gaussian_kernel_array(size, sigma):\n    gaussian_kernel_array = gaussian_kernel(size, sigma)\n    gaussian_kernel_array = gaussian_kernel_array * (255 / gaussian_kernel_array[ int(len(gaussian_kernel_array)/2) ][ int(len(gaussian_kernel_array)/2) ])\n    gaussian_kernel_array = gaussian_kernel_array.astype(int)\n    return gaussian_kernel_array\n\n\ndef create_gt_images(size, sigma, width, height, root_dir='c:/kyoto/TennisML/TrackNet/Dataset', path_output='c:/kyoto/TennisML/TrackNet/Dataset/gts'):\n    for game_id in range(1, 11):\n        path_game = os.path.join(root_dir, f\"game{game_id}\")\n        clips = os.listdir(path_game)\n\n        path_output_game = os.path.join(path_output, f\"game{game_id}\")\n        if not os.path.exists(path_output_game):\n            os.makedirs(path_output_game)\n\n        for clip in clips:\n            path_output_clip = os.path.join(path_output_game, clip)\n            if not os.path.exists(path_output_clip):\n                os.makedirs(path_output_clip)\n\n            labels = pd.read_csv(os.path.join(path_game, clip, 'Label.csv'))\n            for idx in range(len(labels.index)):\n                file_name, visibility, x, y, _ = labels.loc[idx, :]\n                heatmap = np.zeros((width, height, 3), dtype=np.uint8)\n                if visibility != 0:\n                    x, y = int(x), int(y)\n                    for i in range(-size, size+1):\n                        for j in range(-size, size+1):\n                            if x+i >= 0 and x+i < width and y+j >= 0 and y+j < height:\n                                gaussian_kernel_array = generate_gaussian_kernel_array(size, sigma)\n                                temp = gaussian_kernel_array[size+i][size+j]\n                                if temp > 0:\n                                    heatmap[x+i][y+j] = (temp, temp, temp)\n                cv2.imwrite(os.path.join(path_output_clip, file_name), heatmap)\n\n\ndef postprocess(feature_map, scale=2, shape=(360, 640), threshold=127, min_radius=2, max_radius=7):\n    feature_map = np.array(feature_map)\n    feature_map = (feature_map*255).astype(np.uint8)\n    feature_map = feature_map.reshape(shape)\n\n    _, heatmap = cv2.threshold(feature_map, threshold, 255, cv2.THRESH_BINARY)\n    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=min_radius, maxRadius=max_radius)\n\n    x, y = None, None\n    if circles is not None and circles.shape[1] > 0:\n        best_circle = circles[0][0]\n        x = best_circle[0] * scale\n        y = best_circle[0] * scale\n    return x, y\n\n","metadata":{"id":"c97efa7d","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:48.671027Z","iopub.execute_input":"2025-06-28T12:14:48.671257Z","iopub.status.idle":"2025-06-28T12:14:48.694213Z","shell.execute_reply.started":"2025-06-28T12:14:48.671242Z","shell.execute_reply":"2025-06-28T12:14:48.693528Z"}},"outputs":[],"execution_count":61},{"id":"10e8cb46","cell_type":"markdown","source":"## train.py","metadata":{"id":"10e8cb46"}},{"id":"711edaab","cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport time\n# from TrackNet_utils import postprocess\nfrom scipy.spatial import distance\n\n\ndef train(model, train_loader, loss_fn, optimizer, device, epoch, max_iters):\n    # loss_fn = nn.CrossEntropyLoss()\n    start_time = time.time()\n    losses = []\n    # Set the model to training mode\n    model.train()\n\n    for iter_id, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        outputs = model(batch[0].float().to(device))\n        ground_truth = torch.tensor(batch[1], dtype=torch.long, device=device)\n        loss = loss_fn(outputs, ground_truth)\n\n        loss.backward()\n        optimizer.step()\n        # optimizer.zero_grad()\n\n        end_time = time.time()\n        duration = end_time - start_time\n\n        losses.append(loss.item())\n        if iter_id % 10 == 0:\n            print(f\"train | epoch:{epoch}, iteration:{iter_id}/{max_iters}, loss:{round(loss.item(), 6)}, time:{duration}\")\n\n        if iter_id >= max_iters - 1:\n            break\n\n    return np.mean(losses)\n\n\n# Test the accuracy, precision, recall and f1-measure of the prediction\ndef validate(model, val_loader, device, epoch, min_dist=5):\n    '''\n    tp: True Positive\n    fp: False Positive\n    tn: True Negative\n    fn: False Negative\n    '''\n    losses = []\n    tp = [0, 0, 0, 0]\n    fp = [0, 0, 0, 0]\n    tn = [0, 0, 0, 0]\n    fn = [0, 0, 0, 0]\n\n    criterion = nn.CrossEntropyLoss()\n    model.eval()\n\n    for iter_id, batch in enumerate(val_loader):\n        with torch.no_grad():\n            out = model(batch[0].float().to(device))\n            gt = torch.tensor(batch[1], dtype=torch.long, device=device)\n            loss = criterion(out, gt)\n            losses.append(loss.item())\n\n            output = out.argmax(dim=1).detach().cpu().numpy()\n            for i in range(len(output)):\n                x_pred, y_pred = postprocess(output[i])\n                x_gt = batch[2][i]\n                y_gt = batch[3][i]\n                vis = batch[4][i]\n\n                if x_pred is not None and y_pred is not None:\n                    if vis != 0:\n                        if not math.isnan(x_pred) and not math.isnan(y_pred) and not math.isnan(x_gt) and not math.isnan(y_gt):\n                            dist = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n                            if dist < min_dist:\n                                tp[int(vis)] += 1\n                            else:\n                                fp[int(vis)] += 1\n                        else:\n                            fp[int(vis)] += 1\n                    else:\n                        fp[int(vis)] += 1\n                elif vis != 0:\n                    fn[int(vis)] += 1\n                else:\n                    tn[int(vis)] += 1\n\n\n    eps = 1e-15\n\n    total_tp = sum(tp)\n    total_fp = sum(fp)\n    total_tn = sum(tn)\n    total_fn = sum(fn)\n    vc1 = tp[1] + fp[1] + tn[1] + fn[1]\n    vc2 = tp[2] + fp[2] + tn[2] + fn[2]\n    vc3 = tp[3] + fp[3] + tn[3] + fn[3]\n\n    precision = total_tp / (total_tp + total_fp + eps)\n    recall = total_tp / (vc1 + vc2 + vc3 + eps)\n    f1 = 2 * precision * recall / (precision + recall + eps)\n\n    print(f\"precision : {precision}\")\n    print(f\"recall : {recall}\")\n    print(f\"f1 : {f1}\")\n\n    return np.mean(losses), precision, recall, f1\n","metadata":{"id":"711edaab","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:48.695050Z","iopub.execute_input":"2025-06-28T12:14:48.695324Z","iopub.status.idle":"2025-06-28T12:14:48.713354Z","shell.execute_reply.started":"2025-06-28T12:14:48.695301Z","shell.execute_reply":"2025-06-28T12:14:48.712778Z"}},"outputs":[],"execution_count":62},{"id":"f00f9a9e","cell_type":"markdown","source":"## dataset.py","metadata":{"id":"f00f9a9e"}},{"id":"eaee878a","cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nimport cv2\nimport math\n\n\nclass TrackNetDataset(Dataset):\n    def __init__(self, mode, path_dataset, input_height=360, input_width=640):\n        self.path_dataset = path_dataset\n        self.data = pd.read_csv(os.path.join(self.path_dataset, f\"labels_{mode}.csv\"))\n        self.HEIGHT = input_height\n        self.WIDTH = input_width\n        print(f\"mode = {mode}, samples = {self.data.shape[0]}\")\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        path_now, path_prev, path_prevprev, path_gt, x, y, status, visibility = self.data.loc[idx, :]\n\n        path_now = os.path.join(self.path_dataset, path_now)\n        path_prev = os.path.join(self.path_dataset, path_prev)\n        path_prevprev = os.path.join(self.path_dataset, path_prevprev)\n        path_gt = os.path.join(self.path_dataset, 'gts', path_gt)\n\n        if math.isnan(x) or math.isnan(y):\n            x = -1\n            y = -1\n        \n        img_now = cv2.imread(path_now)\n        img_prev = cv2.imread(path_prev)\n        img_prevprev = cv2.imread(path_prevprev)\n\n        img_now = cv2.resize(img_now, (self.WIDTH, self.HEIGHT))\n        img_prev = cv2.resize(img_prev, (self.WIDTH, self.HEIGHT))\n        img_prevprev = cv2.resize(img_prevprev, (self.WIDTH, self.HEIGHT))\n\n        imgs = np.concatenate((img_now, img_prev, img_prevprev), axis=2)\n        imgs = imgs.astype(np.float32)/255.0\n        imgs = np.rollaxis(imgs, 2, 0)\n\n        gt_img = cv2.imread(path_gt)\n        gt_img = cv2.resize(gt_img, (self.WIDTH, self.HEIGHT))\n        gt_img = gt_img[:, :, 0]\n        gt_img = np.reshape(gt_img, (self.WIDTH * self.HEIGHT))\n\n        return imgs, gt_img, x, y, visibility\n","metadata":{"id":"eaee878a","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T12:14:48.714244Z","iopub.execute_input":"2025-06-28T12:14:48.714517Z","iopub.status.idle":"2025-06-28T12:14:48.732473Z","shell.execute_reply.started":"2025-06-28T12:14:48.714494Z","shell.execute_reply":"2025-06-28T12:14:48.731711Z"}},"outputs":[],"execution_count":63},{"id":"5f74d3f6","cell_type":"markdown","source":"## main.py","metadata":{"id":"5f74d3f6"}},{"id":"a3c761e7","cell_type":"code","source":"# from model import TrackNet\nimport torch\nimport torch.nn as nn\n# from dataset import TrackNetDataset\nimport os\n# from train import train, validate\n# from tensorboardX import SummaryWriter\nfrom torch.utils.tensorboard import SummaryWriter\n# import argparse\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n\nif __name__ == '__main__':\n\n    # path_dataset = 'C:/kyoto/TennisML/TrackNet/Dataset'\n    path_dataset = '/kaggle/input/tracknetdataset/Dataset/'\n    batch_size = 2\n    exp_id = '2'\n    num_epochs = 500\n    lr = 1.0\n    val_intervals = 5\n    steps_per_epoch = 200\n\n\n\n    train_dataset = TrackNetDataset(mode='train', path_dataset=path_dataset)\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=1,\n        pin_memory=True\n    )\n\n    val_dataset = TrackNetDataset(mode='val', path_dataset=path_dataset)\n    val_loader = torch.utils.data.DataLoader(\n        val_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=1,\n        pin_memory=True\n    )\n\n    model = TrackNet()\n    device = 'cuda'\n    # device = xm.xla_device()\n    model = model.to(device)\n\n    exps_path = './exps/{}'.format(exp_id)\n    tb_path = os.path.join(exps_path, 'plots')\n    if not os.path.exists(tb_path):\n        os.makedirs(tb_path)\n    log_writer = SummaryWriter(tb_path)\n    model_last_path = os.path.join(exps_path, 'model_last.pt')\n    model_best_path = os.path.join(exps_path, 'model_best.pt')\n\n    optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n    val_best_metric = 0\n\n    for epoch in range(num_epochs):\n        loss_fn = nn.CrossEntropyLoss()\n        train_loss = train(model, train_loader, loss_fn, optimizer, device, epoch, steps_per_epoch)\n        print(f\"train_loss = {train_loss}\")\n        log_writer.add_scalar('Train/training_loss', train_loss, epoch)\n        log_writer.add_scalar('Train/lr', optimizer.param_groups[0]['lr'], epoch)\n\n        if (epoch > 0) and (epoch % val_intervals == 0):\n            val_loss, precision, recall, f1 = validate(model, val_loader, device, epoch)\n            print(f\"val_loss = {val_loss}\")\n            log_writer.add_scalar('Val/loss', val_loss, epoch)\n            log_writer.add_scalar('Val/precision', precision, epoch)\n            log_writer.add_scalar('Val/recall', recall, epoch)\n            log_writer.add_scalar('Val/f1', f1, epoch)\n            if f1 > val_best_metric:\n                val_best_metric = f1\n                torch.save(model.state_dict(), model_best_path)\n            torch.save(model.state_dict(), model_last_path)\n","metadata":{"id":"a3c761e7","colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"756cb309-7bca-4a79-d1f4-77132516d1f5","trusted":true,"execution":{"execution_failed":"2025-06-28T14:47:18.928Z"}},"outputs":[],"execution_count":null}]}