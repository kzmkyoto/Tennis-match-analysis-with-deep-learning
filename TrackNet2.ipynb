{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMqC3v6Jlstz",
        "outputId": "acd36888-bc42-4539-95e7-654820ce7587"
      },
      "id": "KMqC3v6Jlstz",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCm5coNImzQ3",
        "outputId": "580fdafb-aa3f-496a-ff90-177c6b8bcbb2"
      },
      "id": "FCm5coNImzQ3",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "download necessary libraries"
      ],
      "metadata": {
        "id": "3Lm0aFpRGL4w"
      },
      "id": "3Lm0aFpRGL4w"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV6zvfTWl1d2",
        "outputId": "b6bde7e0-029f-412d-a0d1-823ad058fa30"
      },
      "id": "mV6zvfTWl1d2",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: opencv_python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 2)) (4.11.0.86)\n",
            "Requirement already satisfied: pandas==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.15.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 4)) (1.15.3)\n",
            "Requirement already satisfied: tensorboardX==2.6.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 5)) (2.6.4)\n",
            "Requirement already satisfied: torch==2.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (2.7.0)\n",
            "Requirement already satisfied: torchvision==0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 7)) (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.3.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX==2.6.4->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX==2.6.4->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 5)) (5.29.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.22.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.3.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->-r /content/drive/MyDrive/tennis_deep_learning/TrackNet/requirements.txt (line 6)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  print('available')\n",
        "else:\n",
        "  print('not available')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt80DpFQgrXJ",
        "outputId": "7f742c88-dba2-4f30-fccc-2f8e83c70502"
      },
      "id": "rt80DpFQgrXJ",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78f5844b",
      "metadata": {
        "id": "78f5844b"
      },
      "source": [
        "# model training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85f11a17",
      "metadata": {
        "id": "85f11a17"
      },
      "source": [
        "## model.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "56a7349a",
      "metadata": {
        "id": "56a7349a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, pad=1, stride=1, bias=True):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=pad, bias=bias),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TrackNet(nn.Module):\n",
        "    def __init__(self, out_channels=256):\n",
        "        super().__init__()\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=9, out_channels=64)\n",
        "        self.conv2 = ConvBlock(in_channels=64, out_channels=64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n",
        "        self.conv4 = ConvBlock(in_channels=128, out_channels=128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv5 = ConvBlock(in_channels=128, out_channels=256)\n",
        "        self.conv6 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.conv7 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv8 = ConvBlock(in_channels=256, out_channels=512)\n",
        "        self.conv9 = ConvBlock(in_channels=512, out_channels=512)\n",
        "        self.conv10 = ConvBlock(in_channels=512, out_channels=512)\n",
        "        self.ups1 = nn.Upsample(scale_factor=2)\n",
        "        self.conv11 = ConvBlock(in_channels=512, out_channels=256)\n",
        "        self.conv12 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.conv13 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.ups2 = nn.Upsample(scale_factor=2)\n",
        "        self.conv14 = ConvBlock(in_channels=256, out_channels=128)\n",
        "        self.conv15 = ConvBlock(in_channels=128, out_channels=128)\n",
        "        self.ups3 = nn.Upsample(scale_factor=2)\n",
        "        self.conv16 = ConvBlock(in_channels=128, out_channels=64)\n",
        "        self.conv17 = ConvBlock(in_channels=64, out_channels=64)\n",
        "        self.conv18 = ConvBlock(in_channels=64, out_channels=self.out_channels)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x, testing=False):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.ups1(x)\n",
        "        x = self.conv11(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.ups2(x)\n",
        "        x = self.conv14(x)\n",
        "        x = self.conv15(x)\n",
        "        x = self.ups3(x)\n",
        "        x = self.conv16(x)\n",
        "        x = self.conv17(x)\n",
        "        x = self.conv18(x)\n",
        "        # x = self.softmax(x)\n",
        "        out = x.reshape(batch_size, self.out_channels, -1)\n",
        "        if testing:\n",
        "            out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.uniform_(module.weight, -0.05, 0.05)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nn.init.constant_(module.weight, 1)\n",
        "                nn.init.constant_(module.bias, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b92efd6",
      "metadata": {
        "id": "2b92efd6"
      },
      "source": [
        "## TrackNet_utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c97efa7d",
      "metadata": {
        "id": "c97efa7d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def create_gt_labels(root_dir=r'c:/kyoto/TennisML/TrackNet/Dataset', path_csv_output=r'c:/kyoto/TennisML/TrackNet/Dataset', train_propotion=0.7):\n",
        "    # Merge label.csv files in each end of clips to one csv file\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    for game_id in range(1, 11):\n",
        "        path_game = os.path.join(root_dir, f\"game{game_id}\")\n",
        "        clips = os.listdir(path_game)\n",
        "        for clip in clips:\n",
        "            labels = pd.read_csv(os.path.join(path_game, clip, 'Label.csv'))\n",
        "            labels['path_now'] = labels['file name'].apply(lambda k: os.path.join(f\"game{game_id}\", clip, k))\n",
        "\n",
        "            # labels_gt = labels.iloc[2:].copy()      # remove the first two rows\n",
        "            labels_gt = labels.iloc[:].copy()\n",
        "            labels_gt.loc[:, 'path_prev'] = labels['path_now'].shift(1)\n",
        "            labels_gt.loc[:, 'path_prevprev'] = labels['path_now'].shift(2)\n",
        "            labels_gt.loc[:, 'path_gt'] = labels['path_now']\n",
        "            labels_gt = labels_gt[2:]\n",
        "            df = pd.concat([df, labels_gt], ignore_index=True)\n",
        "\n",
        "    df = df.loc[:, ['path_now', 'path_prev', 'path_prevprev', 'path_gt', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n",
        "    num_train = int(len(df.index)*train_propotion)\n",
        "    df_train = df.loc[:num_train]\n",
        "    df_val = df.loc[num_train:]\n",
        "    df_train.to_csv(os.path.join(path_csv_output, 'labels_train.csv'), index=False)\n",
        "    df_val.to_csv(os.path.join(path_csv_output, 'labels_val.csv'), index=False)\n",
        "    # print(df_train)\n",
        "\n",
        "# def create_gt_labels_2(path_input='c:/kyoto/TennisML/TrackNet/Dataset', path_output='c:/kyoto/TennisML/TrackNet/Dataset', train_rate=0.7):\n",
        "#     df = pd.DataFrame()\n",
        "#     for game_id in range(1,11):\n",
        "#         game = 'game{}'.format(game_id)\n",
        "#         clips = os.listdir(os.path.join(path_input, game))\n",
        "#         for clip in clips:\n",
        "#             labels = pd.read_csv(os.path.join(path_input, game, clip, 'Label.csv'))\n",
        "#             labels['gt_path'] = 'gts/' + game + '/' + clip + '/' + labels['file name']\n",
        "#             labels['path1'] = 'images/' + game + '/' + clip + '/' + labels['file name']\n",
        "#             labels_target = labels[2:]\n",
        "#             labels_target.loc[:, 'path2'] = list(labels['path1'][1:-1])\n",
        "#             labels_target.loc[:, 'path3'] = list(labels['path1'][:-2])\n",
        "#             df = pd.concat([df, labels_target], ignore_index=True)\n",
        "#     df = df.reset_index(drop=True)\n",
        "#     df = df[['path1', 'path2', 'path3', 'gt_path', 'x-coordinate', 'y-coordinate', 'status', 'visibility']]\n",
        "#     # df = df.sample(frac=1)\n",
        "#     num_train = int(df.shape[0]*train_rate)\n",
        "#     df_train = df[:num_train]\n",
        "#     df_test = df[num_train:]\n",
        "#     df_train.to_csv(os.path.join(path_output, 'labels_train.csv'), index=False)\n",
        "#     df_test.to_csv(os.path.join(path_output, 'labels_val.csv'), index=False)\n",
        "\n",
        "\n",
        "def gaussian_kernel(size, sigma):\n",
        "    '''\n",
        "    sigma(variance) is equivalent to the average radius of a tennis ball (about 5 pixels)\n",
        "    '''\n",
        "    x, y = np.mgrid[-size:size+1, -size:size+1]\n",
        "    gk = np.exp( -(x**2 + y**2) / (float(2*sigma)) )\n",
        "    return gk\n",
        "\n",
        "def generate_gaussian_kernel_array(size, sigma):\n",
        "    gaussian_kernel_array = gaussian_kernel(size, sigma)\n",
        "    gaussian_kernel_array = gaussian_kernel_array * (255 / gaussian_kernel_array[ int(len(gaussian_kernel_array)/2) ][ int(len(gaussian_kernel_array)/2) ])\n",
        "    gaussian_kernel_array = gaussian_kernel_array.astype(int)\n",
        "    return gaussian_kernel_array\n",
        "\n",
        "\n",
        "def create_gt_images(size, sigma, width, height, root_dir='c:/kyoto/TennisML/TrackNet/Dataset', path_output='c:/kyoto/TennisML/TrackNet/Dataset/gts'):\n",
        "    for game_id in range(1, 11):\n",
        "        path_game = os.path.join(root_dir, f\"game{game_id}\")\n",
        "        clips = os.listdir(path_game)\n",
        "\n",
        "        path_output_game = os.path.join(path_output, f\"game{game_id}\")\n",
        "        if not os.path.exists(path_output_game):\n",
        "            os.makedirs(path_output_game)\n",
        "\n",
        "        for clip in clips:\n",
        "            path_output_clip = os.path.join(path_output_game, clip)\n",
        "            if not os.path.exists(path_output_clip):\n",
        "                os.makedirs(path_output_clip)\n",
        "\n",
        "            labels = pd.read_csv(os.path.join(path_game, clip, 'Label.csv'))\n",
        "            for idx in range(len(labels.index)):\n",
        "                file_name, visibility, x, y, _ = labels.loc[idx, :]\n",
        "                heatmap = np.zeros((width, height, 3), dtype=np.uint8)\n",
        "                if visibility != 0:\n",
        "                    x, y = int(x), int(y)\n",
        "                    for i in range(-size, size+1):\n",
        "                        for j in range(-size, size+1):\n",
        "                            if x+i >= 0 and x+i < width and y+j >= 0 and y+j < height:\n",
        "                                gaussian_kernel_array = generate_gaussian_kernel_array(size, sigma)\n",
        "                                temp = gaussian_kernel_array[size+i][size+j]\n",
        "                                if temp > 0:\n",
        "                                    heatmap[x+i][y+j] = (temp, temp, temp)\n",
        "                cv2.imwrite(os.path.join(path_output_clip, file_name), heatmap)\n",
        "\n",
        "\n",
        "def postprocess(feature_map, scale=2, shape=(360, 640), threshold=127, min_radius=2, max_radius=7):\n",
        "    feature_map = np.array(feature_map)\n",
        "    feature_map = (feature_map*255).astype(np.uint8)\n",
        "    feature_map = feature_map.reshape(shape)\n",
        "\n",
        "    _, heatmap = cv2.threshold(feature_map, threshold, 255, cv2.THRESH_BINARY)\n",
        "    circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=min_radius, maxRadius=max_radius)\n",
        "\n",
        "    x, y = None, None\n",
        "    if circles is not None and circles.shape[1] > 0:\n",
        "        best_circle = circles[0][0]\n",
        "        x = best_circle[0] * scale\n",
        "        y = best_circle[0] * scale\n",
        "    return x, y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e8cb46",
      "metadata": {
        "id": "10e8cb46"
      },
      "source": [
        "## train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "711edaab",
      "metadata": {
        "id": "711edaab"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import time\n",
        "# from TrackNet_utils import postprocess\n",
        "from scipy.spatial import distance\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_fn, optimizer, device, epoch, max_iters):\n",
        "    # loss_fn = nn.CrossEntropyLoss()\n",
        "    start_time = time.time()\n",
        "    losses = []\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for iter_id, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        print('batch[0] : ', batch[0].size(), 'batch[1] : ', batch[1].size())\n",
        "        outputs = model(batch[0].float().to(device))\n",
        "        ground_truth = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "        print('outputs : ', outputs.size(), 'ground_truth : ', ground_truth.size())\n",
        "        outputs = outputs.squeeze(0)\n",
        "        ground_truth = ground_truth.squeeze(0)\n",
        "        print('outputs : ', outputs.size(), 'ground_truth : ', ground_truth.size())\n",
        "        loss = loss_fn(outputs, ground_truth)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # optimizer.zero_grad()\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        print(f'epoch:{epoch}, iteration:{iter_id}/{max_iters}, loss:{round(loss, 5)}, time:{duration}')\n",
        "\n",
        "        if iter_id >= max_iters - 1:\n",
        "            break\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "# Test the accuracy, precision, recall and f1-measure of the prediction\n",
        "def validate(model, val_loader, device, epoch, min_dist=5):\n",
        "    '''\n",
        "    tp: True Positive\n",
        "    fp: False Positive\n",
        "    tn: True Negative\n",
        "    fn: False Negative\n",
        "    '''\n",
        "    losses = []\n",
        "    tp = [0, 0, 0, 0]\n",
        "    fp = [0, 0, 0, 0]\n",
        "    tn = [0, 0, 0, 0]\n",
        "    fn = [0, 0, 0, 0]\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    for iter_id, batch in enumerate(val_loader):\n",
        "        with torch.no_grad():\n",
        "            inputs, gt_heatmap, x_coords, y_coords, visibilities = batch\n",
        "            out = model(batch[0].float().to(device))\n",
        "            # gt = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
        "            gt_heatmap_flat = gt_heatmap.squeeze(1).long().to(device).view(gt_heatmap.size(0), -1)\n",
        "            loss = criterion(out, gt_heatmap_flat)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            output = out.argmax(dim=1).detach().cpu().numpy().reshape(out.size(0), 640, 360)\n",
        "            for i in range(len(output)):\n",
        "                x_pred, y_pred = postprocess(output[i])\n",
        "                # x_gt = batch[2][i]\n",
        "                # y_gt = batch[3][i]\n",
        "                # vis = batch[4][i]\n",
        "                x_gt = x_coords[i]\n",
        "                y_gt = y_coords[i]\n",
        "                vis = visibilities[i]\n",
        "\n",
        "                if x_pred is not None and y_pred is not None:\n",
        "                    if vis != 0:\n",
        "                        if not math.isnan(x_pred) and not math.isnan(y_pred) and not math.isnan(x_gt) and not math.isnan(y_gt):\n",
        "                            dist = distance.euclidean((x_pred, y_pred), (x_gt, y_gt))\n",
        "                            if dist < min_dist:\n",
        "                                tp[int(vis)] += 1\n",
        "                            else:\n",
        "                                fp[int(vis)] += 1\n",
        "                        else:\n",
        "                            fp[int(vis)] += 1\n",
        "                    else:\n",
        "                        fp[int(vis)] += 1\n",
        "                elif vis != 0:\n",
        "                    fn[int(vis)] += 1\n",
        "                else:\n",
        "                    tn[int(vis)] += 1\n",
        "\n",
        "\n",
        "    eps = 1e-15\n",
        "\n",
        "    total_tp = sum(tp)\n",
        "    total_fp = sum(fp)\n",
        "    total_tn = sum(tn)\n",
        "    total_fn = sum(fn)\n",
        "\n",
        "    precision = sum(tp) / (total_tp + total_fp + eps)\n",
        "    recall = total_tp / (total_tp + total_fn + eps)\n",
        "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
        "\n",
        "    print(f\"precision : {precision}\")\n",
        "    print(f\"recall : {recall}\")\n",
        "    print(f\"f1 : {f1}\")\n",
        "\n",
        "    return np.mean(losses), precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f00f9a9e",
      "metadata": {
        "id": "f00f9a9e"
      },
      "source": [
        "## dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eaee878a",
      "metadata": {
        "id": "eaee878a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class TrackNetDataset(Dataset):\n",
        "    def __init__(self, mode, path_dataset, input_height=360, input_width=640):\n",
        "        self.path_dataset = path_dataset\n",
        "        self.data = pd.read_csv(os.path.join(self.path_dataset, f\"labels_{mode}.csv\"))\n",
        "        self.HEIGHT = input_height\n",
        "        self.WIDTH = input_width\n",
        "        print(f\"mode = {mode}, samples = {self.data.shape[0]}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path_now, path_prev, path_prevprev, path_gt, x, y, status, visibility = self.data.loc[idx, :]\n",
        "\n",
        "        path_now = os.path.join(self.path_dataset, path_now)\n",
        "        path_prev = os.path.join(self.path_dataset, path_prev)\n",
        "        path_prevprev = os.path.join(self.path_dataset, path_prevprev)\n",
        "        path_gt = os.path.join(self.path_dataset, 'gts', path_gt)\n",
        "\n",
        "        if math.isnan(x) or math.isnan(y):\n",
        "            x = -1\n",
        "            y = -1\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((self.HEIGHT, self.WIDTH)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        def pil_to_tensor_rgb(path):\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "            img = transform(img)\n",
        "            return img\n",
        "\n",
        "        gt_img = Image.open(path_gt).convert(\"RGB\")\n",
        "        gt_img = transform(gt_img)\n",
        "        gt_img = gt_img[0, :, :]\n",
        "        gt_img = gt_img.reshape(self.HEIGHT * self.WIDTH)\n",
        "        gt_img = (gt_img * 255).byte()\n",
        "\n",
        "        img_now = pil_to_tensor_rgb(path_now)\n",
        "        img_prev = pil_to_tensor_rgb(path_prev)\n",
        "        img_prevprev = pil_to_tensor_rgb(path_prevprev)\n",
        "\n",
        "        imgs = torch.cat((img_now, img_prev, img_prevprev), dim=0)\n",
        "        return imgs, gt_img, x, y, visibility\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f74d3f6",
      "metadata": {
        "id": "5f74d3f6"
      },
      "source": [
        "## main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a3c761e7",
      "metadata": {
        "id": "a3c761e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "756cb309-7bca-4a79-d1f4-77132516d1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mode = train, samples = 13752\n",
            "mode = val, samples = 5894\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-829403390>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# device = xm.xla_device()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mexps_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./exps/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1339\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m                     )\n\u001b[0;32m-> 1341\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1342\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "# from model import TrackNet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# from dataset import TrackNetDataset\n",
        "import os\n",
        "# from train import train, validate\n",
        "from tensorboardX import SummaryWriter\n",
        "# import argparse\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # path_dataset = 'C:/kyoto/TennisML/TrackNet/Dataset'\n",
        "    path_dataset = '/content/drive/MyDrive/tennis_deep_learning/TrackNet/Dataset'\n",
        "    batch_size = 2\n",
        "    exp_id = '1'\n",
        "    num_epochs = 500\n",
        "    lr = 1.0\n",
        "    val_intervals = 5\n",
        "    steps_per_epoch = 200\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = TrackNetDataset(mode='train', path_dataset=path_dataset)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    val_dataset = TrackNetDataset(mode='val', path_dataset=path_dataset)\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=1,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    model = TrackNet()\n",
        "    device = 'cuda'\n",
        "    # device = xm.xla_device()\n",
        "    model = model.to(device)\n",
        "\n",
        "    exps_path = './exps/{}'.format(exp_id)\n",
        "    tb_path = os.path.join(exps_path, 'plots')\n",
        "    if not os.path.exists(tb_path):\n",
        "        os.makedirs(tb_path)\n",
        "    log_writer = SummaryWriter(tb_path)\n",
        "    model_last_path = os.path.join(exps_path, 'model_last.pt')\n",
        "    model_best_path = os.path.join(exps_path, 'model_best.pt')\n",
        "\n",
        "    optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
        "    val_best_metric = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(epoch)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        train_loss = train(model, train_loader, loss_fn, optimizer, device, epoch, steps_per_epoch)\n",
        "        print(f\"train_loss = {train_loss}\")\n",
        "        log_writer.add_scalar('Train/training_loss', train_loss, epoch)\n",
        "        log_writer.add_scalar('Train/lr', optimizer.param_groups[0]['lr'], epoch)\n",
        "\n",
        "        if (epoch > 0) and (epoch % val_intervals == 0):\n",
        "            val_loss, precision, recall, f1 = validate(model, val_loader, device, epoch)\n",
        "            print(f\"val_loss = {val_loss}\")\n",
        "            log_writer.add_scalar('Val/loss', val_loss, epoch)\n",
        "            log_writer.add_scalar('Val/precision', precision, epoch)\n",
        "            log_writer.add_scalar('Val/recall', recall, epoch)\n",
        "            log_writer.add_scalar('Val/f1', f1, epoch)\n",
        "            if f1 > val_best_metric:\n",
        "                val_best_metric = f1\n",
        "                torch.save(model.state_dict(), model_best_path)\n",
        "            torch.save(model.state_dict(), model_last_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}